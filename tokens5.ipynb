{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otter2022/Oil_Marketing_Campaign/blob/main/tokens5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3GxvCkOFUTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904eff1d-6921-4b67-cfb9-0cf0ce2c6881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['Dr', 'Doctor', 'Mr', 'Mrs', 'Ms', 'Miss', 'Prof', 'Professor', 'Sir', 'Madam', 'Dame', 'Lord', 'Lady', 'Rev', 'Reverend', 'Hon', 'Honorable', 'Capt', 'Captain', 'Major', 'Col', 'Colonel', 'Gen', 'General', 'Adm', 'Admiral', 'Sgt', 'Sergeant', 'Lt', 'Lieutenant', 'Chief', 'Officer', 'Judge', 'Magistrate', 'Sen', 'Senator', 'Rep', 'Representative', 'Amb', 'Ambassador', 'Pres', 'President', 'VP', 'Vice President', 'Gov', 'Governor', 'Mayor']\n",
            "['Jr', 'Sr', 'Esq', 'Esquire', 'PhD', 'MD', 'DDS', 'DVM', 'JD', 'CPA', 'RN', 'LPN', 'PE', 'Ret']\n",
            "['V', 'IV', 'III', 'II', 'I']\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "#tokens5\n",
        "import csv\n",
        "import re\n",
        "import sys\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "source_data = '/content/drive/MyDrive/ColabNotebooks/FinalProject_AI/Source_Data/'\n",
        "source_data_output = '/content/drive/MyDrive/ColabNotebooks/FinalProject_AI/Source_Data_Output/'\n",
        "source_code = '/content/drive/MyDrive/ColabNotebooks/FinalProject_AI/Source_Code/'\n",
        "admin = '/content/drive/MyDrive/ColabNotebooks/FinalProject_AI/Admin/'\n",
        "backups = '/content/drive/MyDrive/ColabNotebooks/FinalProject_AI/Backups/'\n",
        "\n",
        "#The lists contained in the marketing_compaign_oil.py file serves as a header for name pre-processing\n",
        "#contains exclude, compiled_patterns for exclude, fix_abbreviations, honorifics, suffixes, suffixes_roman, etc.\n",
        "marketing_campaign_oil = source_code+'marketing_campaign_oil.py'\n",
        "with open(marketing_campaign_oil, 'r') as f:\n",
        "    exec(f.read())\n",
        "    f.close()\n",
        "\n",
        "input_file = source_data + 'tokens5_2620_CSV.csv'\n",
        "#input_file = basepath + 'tokens2_test_csv.csv'\n",
        "output_file = source_data_output + 'tokens5_formatted_output.csv'\n",
        "\n",
        "# Test for successul package import marketing_campaign_oil\n",
        "print(honorifics)\n",
        "print(suffixes)\n",
        "print(suffixes_roman)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_excluded(input_string):\n",
        "    # Check if any compiled pattern matches the input string\n",
        "    #I want to print the input_strings that are excluded\n",
        "    for pattern in compiled_patterns:\n",
        "        if pattern.match(input_string):\n",
        "            print(f\"Excluded: {input_string}\")\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def abbreviate(token):\n",
        "  if token in fix_abbreviations.keys():\n",
        "    return fix_abbreviations[token]\n",
        "  else:\n",
        "    return token\n",
        "\n",
        "\n",
        "def rearrange_tokens(name):\n",
        "    # Split the name into tokens\n",
        "    tokens = name.split()\n",
        "\n",
        "    # Process each token to fix abbreviations\n",
        "    tokens = [abbreviate(token.strip()) for token in tokens]\n",
        "\n",
        "    # Capitalize each token appropriately\n",
        "    tokens = [token.capitalize() if token not in suffixes_roman else token for token in tokens]\n",
        "\n",
        "    if len(tokens) == 5:\n",
        "        token1, token2, token3, token4, token5 = tokens[0], tokens[1], tokens[2], tokens[3], tokens[4]\n",
        "\n",
        "        # Exclude if any token for the owner name is in the exclude list\n",
        "        for token in tokens:\n",
        "          if is_excluded(token):\n",
        "            print(f\"Excluded: {name}\")\n",
        "            return \"Miss\"\n",
        "\n",
        "        if token1 in honorifics and token2.isalpha() and token3.isalpha() and token4.isalpha() and (token5 in suffixes or token5 in suffixes_roman):#Mr. Smith John A (Jr/IV)\n",
        "          return f\"{token1} {token3} {token4} {token2} {token5}\"\n",
        "        elif token1 in honorifics and token2.isalpha() and token3.isalpha() and token4.isalpha() and (token5 not in suffixes and token5 not in suffixes_roman):#Mr. Smith John A (Jr/IV)\n",
        "          return f\"{token1} {token3} {token2} {token4} {token5}\"\n",
        "        elif re.search(r'[#\\d\\-]', token2):#token 2 contains at least 1 digit number, keep order\n",
        "          return f\"{token1} {token2} {token3} {token4} {token5}\"\n",
        "        elif token2 == '&':\n",
        "          return f\"{token3} {token4} {token2} {token1} {token5}\"\n",
        "        elif token2 == 'and':\n",
        "          return f\"{token1} {token2} {token3} {token4} {token5}\"\n",
        "        elif (token3 in suffixes or token3 in suffixes_roman) and (token4 == 'and' or token4 == '&'):\n",
        "          return f\"{token5} {token4} {token2} {token1} {token3}\"\n",
        "        elif token2 in fix_abbreviations.values() and token3 == \"Trust\":\n",
        "          return f\"{token1} {token2} {token3} {token4} {token5}\"\n",
        "        elif token2 == \"Family\":\n",
        "          return f\"{token1} {token2} {token3} {token4} {token5}\"\n",
        "        elif token2 != \"Family\" and token3 == \"Trust\":\n",
        "          return f\"{token2} {token1} {token3} {token4} {token5}\"\n",
        "        elif token2 not in fix_abbreviations.values() and re.search(r'[#\\d\\-]', token3):\n",
        "          return f\"{token2} {token1} {token3} {token4} {token5}\"\n",
        "        elif (token3 in fix_abbreviations.values()) and (token4 == \"Trust\"):\n",
        "          return f\"{token1} {token2} {token3} {token4} {token5}\"\n",
        "        elif (token3 not in fix_abbreviations.values()) and (token4 == \"Trust\"):\n",
        "          return f\"{token2} {token3} {token1} {token4} {token5}\"\n",
        "        elif (token3 == \"&\" or token3 == 'and') and  (token4 not in fix_abbreviations.values() and token5 not in fix_abbreviations.values()):\n",
        "          return f\"{token2} {token3} {token4} {token5} {token1}\"\n",
        "        elif re.search(r'[#\\d\\-]', token4):\n",
        "          return f\"{token2} {token3} {token1} {token4} {token5}\"\n",
        "        elif token4 == '&' or token4 == 'and':\n",
        "          return f\"{token2} {token3} {token4} {token5} {token1}\"\n",
        "        elif token5 == \"Trust\":\n",
        "          return f\"{token2} {token3} {token1} {token4} {token5}\"\n",
        "        else:\n",
        "          return f\"{token1} {token2} {token3} {token4} {token5}\"#catch-all\n",
        "    return \"Miss\"\n",
        "\n",
        "\n",
        "def process_names(input_file, output_file):\n",
        "    with open(input_file, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        # OwnerNames in 1st col\n",
        "        names = [row[0] for row in reader]\n",
        "\n",
        "    # Process the names\n",
        "    names = [name.strip() for name in names]\n",
        "\n",
        "    formatted_names = [(name, rearrange_tokens(name)) for name in names]\n",
        "    misses = 0\n",
        "    total = len(formatted_names)\n",
        "\n",
        "    # Try different methods if the above one fails\n",
        "    try:\n",
        "        with open(output_file, 'w', newline='') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow(['column1', 'column2'])  # Write headers\n",
        "            for original, rearranged in formatted_names:\n",
        "                if rearranged == 'Miss':\n",
        "                    misses += 1\n",
        "                else:\n",
        "                    writer.writerow([original, rearranged])\n",
        "    except TypeError:\n",
        "        with open(output_file, 'w') as csvfile:\n",
        "            writer = csv.writer(csvfile)\n",
        "            writer.writerow(['column1', 'column2'])  # Write headers\n",
        "            for original, rearranged in formatted_names:\n",
        "                if rearranged == 'Miss':\n",
        "                    misses += 1\n",
        "                else:\n",
        "                    writer.writerow([original, rearranged])\n",
        "\n",
        "    return misses, total\n",
        "\n"
      ],
      "metadata": {
        "id": "XYNx4_omFcto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    misses,total = process_names(input_file, output_file)\n",
        "    print(f\"Total: {total}\")\n",
        "    print(f\"Errors: {misses}\")\n",
        "    print(f\"Miss percentage {(float(misses)/float(total))*100.00}%.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkDgnu8nFcEL",
        "outputId": "8732d6d8-e639-45da-ee4f-b035577b37e6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excluded: Deceased\n",
            "Excluded: GILL JOE P U/W/O DECEASED\n",
            "Excluded: Corpus\n",
            "Excluded: CORPUS CHRISTI MUS OF SCIENCE\n",
            "Excluded: Deceased\n",
            "Excluded: GREEN CHARLES C JR DECEASED\n",
            "Excluded: Deceased\n",
            "Excluded: HARWIT MARY BLOUNDT - DECEASED\n",
            "Excluded: Deceased\n",
            "Excluded: BRISTOW SARAH SOBOR - DECEASED\n",
            "Excluded: Deceased\n",
            "Excluded: PERRY W B JR DECEASED\n",
            "Excluded: Energy-dorcus\n",
            "Excluded: SM ENERGY-DORCUS JANEY (SA) W\n",
            "Excluded: Energy-dorcus\n",
            "Excluded: SM ENERGY-DORCUS WILMA (SA) J\n",
            "Excluded: Management\n",
            "Excluded: NEAL ROBERT L MANAGEMENT TRUST\n",
            "Excluded: Fndt\n",
            "Excluded: ST DAVID COMMUNITY HEALTH FNDT\n",
            "Excluded: Survivors\n",
            "Excluded: RAUCH ROBERT W SURVIVORS TRUST\n",
            "Excluded: Survivors\n",
            "Excluded: THW & ADW SURVIVORS TRUST\n",
            "Excluded: Survivors\n",
            "Excluded: WYCOFF ROBERT E SURVIVORS TR\n",
            "Total: 2620\n",
            "Errors: 13\n",
            "Miss percentage 0.4961832061068702%.\n"
          ]
        }
      ]
    }
  ]
}